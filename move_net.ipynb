{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('tensorflow': conda)"
  },
  "interpreter": {
   "hash": "1142c7b970321c2569bfb9aa0178a6eee1ad376a0c289b718c0f18531f161718"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt \n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"lite-model_movenet_singlepose_lightning_3.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Keypoints\n",
    "def draw_keypoints(frame, keypoints, conf_thresh):\n",
    "    h, w, _ = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [h, w, 1]))\n",
    "    for landmark in shaped:\n",
    "        ky, kx, conf = landmark\n",
    "        if conf > conf_thresh:\n",
    "            cv.circle(frame, (int(kx), int(ky)), 4, (0, 0, 255), -1)\n",
    "\n",
    "    \n",
    "# Draw edges\n",
    "\n",
    "edges = {\n",
    "     (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}\n",
    "def draw_connections(frame, keypoints, edges, conf_thresh=0.4):\n",
    "    h, w, _ = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [h, w, 1]))\n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, conf1 = shaped[p1]\n",
    "        y2, x2, conf2 = shaped[p2]\n",
    "        if (conf1 >= conf_thresh) & (conf2 >= conf_thresh):\n",
    "            cv.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255,0,0), 2 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(1)\n",
    "while cap.isOpened():\n",
    "    _, frame = cap.read()\n",
    "    # Reshape image\n",
    "    img = frame.copy()\n",
    "    image = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192, 192)\n",
    "\n",
    "    # cast image as tf.float32\n",
    "    input_image = tf.cast(image, dtype=tf.float32)\n",
    "\n",
    "    #setup input and output\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # make predictions\n",
    "    interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "    interpreter.invoke()\n",
    "    # output\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    #Redering\n",
    "    draw_keypoints(frame, keypoints_with_scores, conf_thresh=0.2)\n",
    "    draw_connections(frame, keypoints_with_scores, edges, conf_thresh=0.5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cv.imshow(\"Movenet - Lightening\", frame)\n",
    "    if cv.waitKey(10) & 0xFF==ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}